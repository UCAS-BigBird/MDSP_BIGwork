from pandas import read_csv

from pandas import DataFrame
from pandas import  concat
# load data
#    return datetime.strptime(x, '%Y %m %d %H')
# dataset = read_csv(r'C:\Users\UCAS_BigBird\Desktop\raw.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)
# dataset.drop('No', axis=1, inplace=True)
# # manually specify column names
# dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']
# dataset.index.name = 'date'
#  # mark all NA values with 0
# dataset['pollution'].fillna(0, inplace=True)
#  # drop the first 24 hours
# dataset = dataset[24:]
# #summarize first 5 rows
# print(dataset.head(5))
# # save to file
# dataset.to_csv(r'C:\Users\UCAS_BigBird\Desktop\pollution.csv')
from pandas import read_csv
from matplotlib import pyplot
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
import  matplotlib.pyplot as plt
import numpy

def series_to_supervised(data,n_in=1,n_out=1,dropnan=True):
    n_vars = 1 if type(data) is list else data.shape[1]
    df = DataFrame(data)
    cols, names = list(), list()
    # input sequence (t-n, ... t-1)
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
    # forecast sequence (t, t+1, ... t+n)
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
        # put it all together
    agg = concat(cols, axis=1)
    agg.columns = names
    if dropnan:
        agg.dropna(inplace=True)
    return agg

def rmse(predictions, targets):
    return numpy.sqrt(((predictions - targets) ** 2).mean())

dataset = read_csv(r'C:\Users\UCAS_BigBird\Desktop\kalman_ou.csv')
print(dataset.head())
values = dataset.values
print(values.shape)
values = values.astype('float32')
reframed = series_to_supervised(values, 1, 1)
values=reframed.values
train = values[:700, :]
test = values[300:, :]
print(train.shape)
# split into input and outputs
train_X, train_y = train[:, :-1], train[:, -1]
test_X, test_y = test[:, :-1], test[:, -1]
# reshape input to be 3D [samples, timesteps, features]
train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))
test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))
print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)

model = Sequential()
model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))
model.add(Dense(1))
model.compile(loss='mae', optimizer='adam')
# fit network
history = model.fit(train_X, train_y, epochs=1000, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)
plt.figure(figsize=(16,16),dpi=80)
plt.subplot(2,1,1)
plt.plot(history.history['loss'], 'r-',label='train')
plt.plot(history.history['val_loss'],'ko', label='test')
plt.legend()


plt.subplot(2,1,2)
yhat = model.predict(test_X)
plt.plot(test_y, 'r-',label='train')
plt.plot(yhat,'ko', label='test')
plt.show()
dd=rmse(yhat,test_y)
print(dd)
